---
layout: post
title: Spark-base
category: study
tags: 
description:
---

## Introduction

Apache Spark is a fast and general-purpose cluster computing system. It provides high-level APIs in Java, Scala, Python and R, and an optimized engine that supports general execution graphs. It also supports a rich set of higher-level tools including Spark SQL for SQL and structured data processing, MLlib for machine learning, GraphX for graph processing, and Spark Streaming.

![spark]({{site.url}}/assets/image/interview/29.jpg)

## Environmental construction
编译
```
vim pom.xml
<repository>
<id>cloudera</id>
<url>https://repository.cloudera.com/artifactory/cloudera-repos/</url>
</repository>

1)
vim MAVEN_OPTS
export MAVEN_OPTS="-Xmx2g -XX:ReservedCodeCacheSize=512m"

./build/mvn -Pyarn -Phadoop-2.6 -Phive -Phive-thriftserver -Dhadoop.version=2.6.0-cdh5.7.0 -DskipTests clean package

2)
./dev/make-distribution.sh --name 2.6.0-cdh5.7.0 --tgz -Pyarn -Phadoop-2.6 -Phive -Phive-thriftserver -Dhadoop.version=2.6.0-cdh5.7.0

#运行spark
./spark-shell --master local[2]
```

配置
```
vim spark-env.sh
SPARK_MASTER_HOST=newcome
SPARK_WORKER_CORES=2
SPARK_WORKER_MEMORY=2g
SPARK_WORKER_INSTANCES=2

#standalone不需要
vim slaves
hadoop001
hadoop002
...

./sbin/start-all.sh
./bin/spark-shell --master spark://newcome:7077
```

## wordCount简单使用
```
val file = spark.sparkContext.textFile("file:///Users/newcome/development/devtmp/phone")

val wordCounts = file.flatMap(line => line.split(" ")).map((word => (word, 1))).reduceByKey(_ + _)
wordCounts.collect
```

## spark on yarn

### YARN-Client

- 在Yarn-client中，Driver运行在Client上，通过ApplicationMaster向RM获取资源。本地Driver负责与所有的executor container进行交互，并将最后的结果汇总。结束掉终端，相当于kill掉这个spark应用。
- 日志会直接输出到控制台上
![Spark]({{site.url}}/assets/image/interview/33.png)
![Spark]({{site.url}}/assets/image/interview/34.png)

#### 流程
- Spark Yarn Client向YARN的ResourceManager申请启动Application Master。同时在SparkContent初始化中将创建DAGScheduler和TASKScheduler等，由于我们选择的是Yarn-Client模式，程序会选择YarnClientClusterScheduler和YarnClientSchedulerBackend
- ResourceManager收到请求后，在集群中选择一个NodeManager，为该应用程序分配第一个Container，要求它在这个Container中启动应用程序的ApplicationMaster，与YARN-Cluster区别的是在该ApplicationMaster不运行SparkContext，只与SparkContext进行联系进行资源的分派
- Client中的SparkContext初始化完毕后，与ApplicationMaster建立通讯，向ResourceManager注册，根据任务信息向ResourceManager申请资源（Container）
- 一旦ApplicationMaster申请到资源（也就是Container）后，便与对应的NodeManager通信，要求它在获得的Container中启动CoarseGrainedExecutorBackend，CoarseGrainedExecutorBackend启动后会向Client中的SparkContext注册并申请Task
- client中的SparkContext分配Task给CoarseGrainedExecutorBackend执行，CoarseGrainedExecutorBackend运行Task并向Driver汇报运行的状态和进度，以让Client随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务
- 应用程序运行完成后，Client的SparkContext向ResourceManager申请注销并关闭自己


### Yarn-Cluster
- 第一个阶段是把Spark的Driver作为一个ApplicationMaster在YARN集群中先启动；
- 第二个阶段是由ApplicationMaster创建应用程序，然后为它向ResourceManager申请资源，并启动Executor来运行Task，同时监控它的整个运行过程，直到运行完成

![Spark]({{site.url}}/assets/image/interview/35.png)
![Spark]({{site.url}}/assets/image/interview/36.png)

#### 流程
- Spark Yarn Client向YARN中提交应用程序，包括ApplicationMaster程序、启动ApplicationMaster的命令、需要在Executor中运行的程序等
- ResourceManager收到请求后，在集群中选择一个NodeManager，为该应用程序分配第一个Container，要求它在这个Container中启动应用程序的ApplicationMaster，其中ApplicationMaster进行SparkContext等的初始化
- ApplicationMaster向ResourceManager注册，这样用户可以直接通过ResourceManage查看应用程序的运行状态，然后它将采用轮询的方式通过RPC协议为各个任务申请资源，并监控它们的运行状态直到运行结束
- 一旦ApplicationMaster申请到资源（也就是Container）后，便与对应的NodeManager通信，要求它在获得的Container中启动CoarseGrainedExecutorBackend，而Executor对象的创建及维护是由CoarseGrainedExecutorBackend负责的，CoarseGrainedExecutorBackend启动后会向ApplicationMaster中的SparkContext注册并申请Task。这一点和Standalone模式一样，只不过SparkContext在Spark Application中初始化时，使用CoarseGrainedSchedulerBackend配合YarnClusterScheduler进行任务的调度，其中YarnClusterScheduler只是对TaskSchedulerImpl的一个简单包装，增加了对Executor的等待逻辑等
- ApplicationMaster中的SparkContext分配Task给CoarseGrainedExecutorBackend执行，CoarseGrainedExecutorBackend运行Task并向ApplicationMaster汇报运行的状态和进度，以让ApplicationMaster随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务
 - 应用程序运行完成后，ApplicationMaster向ResourceManager申请注销并关闭自己

 ### 比较
- YarnCluster的Driver是在集群的某一台NM上，但是Yarn-Client就是在RM的机器上； 
- 而Driver会和Executors进行通信，所以Yarn_cluster在提交App之后可以关闭Client，而Yarn-Client不可以； 
- Yarn-Cluster适合生产环境，Yarn-Client适合交互和调试。

### 命令

client模式
```
$ ./bin/spark-submit 
    --class org.apache.spark.examples.SparkPi \
    --master yarn \
    --executor-memory 2g \
    --executor-cores 1 \
    --queue thequeue \
    examples/jars/spark-examples*.jar \
    10    #参数
```

cluster模式
```
$ ./bin/spark-submit 
    --class org.apache.spark.examples.SparkPi \
    --name 方法名 \
    --master yarn-cluster \
    --executor-memory 2g \
    --executor-cores 1 \
    --queue thequeue \
    -- files /home/lib/house.csv,/home/lib/house2.xlsx
    examples/jars/spark-examples*.jar \
    10    #参数

#调试日志
yarn logs -applicationId <app ID>
```