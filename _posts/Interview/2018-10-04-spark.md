---
layout: post
title: Spark-base
category: study
tags: 
description:
---

## Introduction

Apache Spark is a fast and general-purpose cluster computing system. It provides high-level APIs in Java, Scala, Python and R, and an optimized engine that supports general execution graphs. It also supports a rich set of higher-level tools including Spark SQL for SQL and structured data processing, MLlib for machine learning, GraphX for graph processing, and Spark Streaming.

![spark]({{site.url}}/assets/image/interview/29.jpg)

## Environmental construction
运行
```
vim pom.xml
<repository>
<id>cloudera</id>
<url>https://repository.cloudera.com/artifactory/cloudera-repos/</url>
</repository>

1)
vim MAVEN_OPTS
export MAVEN_OPTS="-Xmx2g -XX:ReservedCodeCacheSize=512m"

./build/mvn -Pyarn -Phadoop-2.6 -Phive -Phive-thriftserver -Dhadoop.version=2.6.0-cdh5.7.0 -DskipTests clean package

2)
./dev/make-distribution.sh --name 2.6.0-cdh5.7.0 --tgz -Pyarn -Phadoop-2.6 -Phive -Phive-thriftserver -Dhadoop.version=2.6.0-cdh5.7.0

#运行spark
./spark-shell --master local[2]
```

配置
```
vim spark-env.sh
SPARK_MASTER_HOST=newcome
SPARK_WORKER_CORES=2
SPARK_WORKER_MEMORY=2g
SPARK_WORKER_INSTANCES=2

#standalone不需要
vim slaves
hadoop001
hadoop002
...

./bin/spark-shell --master spark://newcome:7077

./sbin/start-all.sh
```

## wordCount简单使用
```
val file = spark.sparkContext.textFile("file:///Users/newcome/development/devtmp/phone")

val wordCounts = file.flatMap(line => line.split(" ")).map((word => (word, 1))).reduceByKey(_ + _)
wordCounts.collect
```
