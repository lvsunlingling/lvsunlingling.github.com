---
layout: post
title: hadoop-yarn
category: 学习
tags: 
description:
---

## 简介

YARN不仅仅是Hadoop的资源调度框架，还成为一个通用的资源调度管理器

## YARN 架构

![HDFS架构]({{site.url}}/assets/image/interview/14.gif)

### ResourceManager :RM
- 整个集群同一时间提供服务的只有RM一个,负责集群资源的统一管理与调度
- 处理客户端的请求: 提交一个作业,杀死一个作业
- 监控NM,一旦某个NM挂了,那么在NM上运行的任务需要告诉我们AM该如何进行处理

### NodeManeger: NM
- 一个集群有多个,负责本身节点的资源管理与使用
- 定时想RM汇报资源的使用情况
- 接收处理啊来自RM的各种命令: eg:启动Container
- 处理来自AM的命令
- 单个节点的资源管理

### ApplicationMaster:AM
- 每个应用程序对应一个: eg: MR .spark 负责应用程序的管理
- 为应用程序向RM申请资源(core memory)分给内部的task
- 需要与NM同学: eg:启动/停止 task,task运行在container里面, AM也是运行在container

### Container
- 封装了CPU Memory等资源的一个容器
- 是一个任务运行环境的抽象

### Client
- 提交作业
- 查询作业的进度
- 杀死作业

## YARN的执行流程
![yarn流程]({{site.url}}/assets/image/interview/15.jpg)

1. 客户端向yarn提交作业，首先找 RM 分配资源；

2. RM 接收到作业以后，会与对应的 NM 建立通信；

3. RM 要求 NM 创建一个 Container 来运行 ApplicationMaster 实例；

4. ApplicationMaster 会向 RM 注册并申请所需资源，这样 Client 就可以通过 RM 获知作业运行情况；

5. RM 分配给 ApplicationMaster 所需资源，ApplicationMaster 在对应的 NM 上启动 Container；

6. Container 启动后开始执行任务，ApplicationMaster 监控各个任务的执行情况并反馈给 RM；

其中 ApplicationMaster 是可插拔的，可以替换为不同的应用程序。


## YARN环境的搭建
- vi etc/hadoop/mapred-site.xml

```
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>
```

- vi etc/hadoop/yarn-site.xml

```
<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
</configuration>
```

- sbin/start-yarn.sh

- 检测

```
[root@hadoop000 hadoop-2.6.0-cdh5.7.0]# jps
3032 NameNode
3128 DataNode
6089 ResourceManager
6169 NodeManager
3322 SecondaryNameNode
6204 Jps
```

```
http://localhost:8088/
```

- 停止

```
sbin/stop-yarn.sh
```

## 提交mr

```
/hadoop jar /root/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0-cdh5.7.0.jar pi 2 3
```

