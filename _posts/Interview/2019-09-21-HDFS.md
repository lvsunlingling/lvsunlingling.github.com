---
layout: post
title: 大数据-HDFS
category: 学习
tags: 
description:
---

# 一、HDFS

Hadoop实现了一个分布式的文件系统 Hadoop Distributed File System(HDFS)

## HDFS架构
![HDFS架构]({{site.url}}/assets/image/interview/10.png)
### NameNode and DataNode 
一个系统有 1个Master(NameNode) + N个Slaves(DataNode)

一个文件会被拆分多个Block(Blocksize:128m)
 
NameNode负责

1. 客户端请求的相应
2. 元数据(文件的名称 副本系数 Block存放的DN) 的管理

DataNode

1. 存储用户的文件对应数据块(Block)
2. 要定期向NN发送心跳信息,汇报本身及其所有的Block信息,健康状况

---
建议:NameNode和DataNode部署在不同的节点上
```
A typical deployment has a dedicated machine that runs only the NameNode software. Each of the other machines in the cluster runs one instance of the DataNode software. 
```
```
The architecture does not preclude running multiple DataNodes on the same machine but in a real deployment that is rarely the case.
```

### The File System NameSpace
```
An application can specify the number of replicas of a file that should be maintained by HDFS. The number of copies of a file is called the replication factor of that file. This information is stored by the NameNode.
```
*replication factor*: 副本系数 副本因子 

### Data Replication(数据复制)
```
All blocks in a file except the last block are the same size(128m)
```

## 存放策略
![存放策略]({{site.url}}/assets/image/interview/11.png)

## 搭建 HDFS (伪分布式)

### 环境
- centos 6
- hadhoop-2.6.0-cdh5.7.0
- jdk8

### 步骤
1. 安装jdk
- tar -zxvf jdk-8u181-linux-x64.tar.gz -C app/
- vim ~/.bash_profile
```
export JAVA_HOME=/root/app/jdk1.8.0_181
export PATH=$JAVA_HOME/bin:$PATH
```
- source ~/.bash_profile

2. 安装ssh
- sudo yum install ssh
- ssh-keygen -t rsa
- cp ~/.ssh/id_rsa.pub ~/.ssh/authorized_keys

3. 安装hadoop
- tar -zxvf hadoop-2.6.0-cdh5.7.0.tar.gz -C ~/app/
- cd etc/hadoop/
- vim hadoop-env.sh
```
export JAVA_HOME=/root/app/jdk1.8.0_181
```    
vim etc/hadoop/core-site.xml:
```
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:8020</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/root/app/tmp</value>
    </property>
</configuration>
```

vim etc/hadoop/hdfs-site.xml:
```
 <configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
</configuration>
```


vim slaves

- 启动hdfs 第一次执行 hdfs namenode -format
- 启动hdfs sbin/start-dfs.sh
- 验证是否启动 jps
- 访问50070控制台
- 关闭hdfs sbin/stop-dfs.sh

## 使用

### shell命令
eg: hadoop fs -ls /
- ls (-R 递归显示)
- get
- mkdir (-p 递归创建文件夹)
- rm (-R 递归删除文件夹)
- put (本地或者HDFS上的文件拷贝到HDFS中)
- copyFromLocal(本地文件拷贝到HDFS中)
- text 查看文本 
- cat  
