---
layout: post
title: hadoop-hdfs
category: study
tags: 
description:
---

## 简介

Hadoop实现了一个分布式的文件系统 Hadoop Distributed File System(HDFS)

## HDFS架构
![HDFS架构]({{site.url}}/assets/image/interview/10.png)
### NameNode and DataNode 
一个系统有 1个Master(NameNode) + N个Slaves(DataNode)

一个文件会被拆分多个Block(Blocksize:128m)
 
NameNode负责
git
1. 客户端请求的相应
2. 元数据(文件的名称 副本系数 Block存放的DN) 的管理

DataNode

1. 存储用户的文件对应数据块(Block)
2. 要定期向NN发送心跳信息,汇报本身及其所有的Block信息,健康状况

---
建议:NameNode和DataNode部署在不同的节点上

     A typical deployment has a dedicated machine that runs only the NameNode software. Each of the other machines in the cluster runs one instance of the DataNode software. 


     The architecture does not preclude running multiple DataNodes on the same machine but in a real deployment that is rarely the case.


### The File System NameSpace

    An application can specify the number of replicas of a file that should be maintained by HDFS. The number of copies of a file is called the replication factor of that file. This information is stored by the NameNode.

*replication factor*: 副本系数 副本因子 

### Data Replication(数据复制)

    All blocks in a file except the last block are the same size(128m)


## 存放策略
![存放策略]({{site.url}}/assets/image/interview/11.png)

## 搭建 HDFS (伪分布式)

### 环境
- centos 6
- hadhoop-2.6.0-cdh5.7.4
```
http://archive-primary.cloudera.com/cdh5/cdh/5/hadoop-2.6.0-cdh5.7.4.tar.gz
```
- jdk8

### 步骤
1.配置linux虚拟机
- service iptables stop
- hostname设置
```
vi /etc/sysconfig/network
NETWORKING=yes
HOSTNAME=hadoop000
```
- 配置hostname和ip地址的映射关系
```
vi /etc/hosts
内网ip hadoop000
```

2. 安装jdk
- tar -zxvf jdk-8u181-linux-x64.tar.gz -C app/
- vim ~/.bash_profile
```
export JAVA_HOME=/root/app/jdk1.8.0_181
export PATH=$JAVA_HOME/bin:$PATH
```
- source ~/.bash_profile

3. 安装ssh
- sudo yum install ssh
- ssh-keygen -t rsa
- cp ~/.ssh/id_rsa.pub ~/.ssh/authorized_keys

4. 安装hadoop
- tar -zxvf hadoop-2.6.0-cdh5.7.0.tar.gz -C ~/app/
- cd etc/hadoop/
- vim hadoop-env.sh

```
export JAVA_HOME=/root/app/jdk1.8.0_181
```    

vim etc/hadoop/core-site.xml:

```
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://hadoop000:8020</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/root/app/tmp</value>
    </property>
</configuration>
```

vim etc/hadoop/hdfs-site.xml:

```
 <configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
</configuration>
```

vim slaves
```
hadoop000
```

- 启动hdfs 第一次执行 hdfs namenode -format
- 启动hdfs sbin/start-dfs.sh
- 验证是否启动 jps
- 访问50070控制台
- 关闭hdfs sbin/stop-dfs.sh

## 使用

### shell命令
eg: hadoop fs -ls /
- ls (-R 递归显示)
- get
- mkdir (-p 递归创建文件夹)
- rm (-R 递归删除文件夹)
- put (本地或者HDFS上的文件拷贝到HDFS中)
- copyFromLocal(本地文件拷贝到HDFS中)
- text 查看文本 
- cat  

## java Api
[代码](https://github.com/almostlie/hadooptrain/blob/master/src/test/java/com/newcome/hadoop/HDFSApp.java)

## HDFS 的读写流程

### 读
![读]({{site.url}}/assets/image/interview/12.jpg)
1. 打开分布式文件：调用分布式文件 DistributedFileSystem.open( ) 方法；
2. 寻址请求：从 NameNode 处得到 DataNode 的地址，DistributedFileSystem使用 RPC 方式调用了NameNode，NameNode 返回存有该副本的DataNode 地址，DistributedFileSystem 返回了一个输入流对象（FSDataInputStream），该对象封装了输入流 DFSInputStream；
3. 连接到DataNode：调用输入流 FSDataInputStream.read( ) 方法从而让DFSInputStream 连接到 DataNodes；
4. 从 DataNode 中获取数据：通过循环调用 read( ) 方法，从而将数据从 DataNode 传输到客户端；
5. 读取另外的 DataNode 直到完成：到达块的末端时候，输入流 DFSInputStream 关闭与 DataNode 连接， 寻找下一个 DataNode；
完成读取，关闭连接：即调用输入流 FSDataInputStream.close( )；


### 写 
![写]({{site.url}}/assets/image/interview/13.jpg)
1. 发送创建文件请求：调用分布式文件系统 DistributedFileSystem.create( )方法；
NameNode 创建文件记录：分布式文件系统 DistributedFileSystem 发送 RPC 请求给 NameNode，NameNode 检查权限后创建一条记录，返回输出流 FSDataOutputStream，封装了输出流 DFSOutputDtream；
2. 客户端写入数据：输出流 DFSOutputDtream 将数据分成一个个的数据包，并写入内部队列。DataStreamer 根据 DataNode 列表来要求 NameNode 分配适合的新块来存储数据备份。 一组 DataNode 构成管线(管线的 DataNode 之间使用 Socket 流式通信)；
3. 使用管线传输数据：DataStreamer 将数据包流式传输到管线第一个DataNode，第一个 DataNode 再传到第二个DataNode，直到完成；
确认队列：DataNode 收到数据后发送确认，管线的 DataNode 所有的确认组成一个确认队列。所有 DataNode 都确认，管线数据包删除；
4. 关闭：客户端对数据量调用 close( ) 方法。将剩余所有数据写入DataNode管线，联系NameNode并且发送文件写入完成信息之前等待确认；
NameNode确认：
5. 故障处理：若过程中发生故障，则先关闭管线，把队列中所有数据包添加回去队列，确保数据包不漏。为另一个正常 DataNode 的当前数据块指定一个新的标识，并将该标识传送给 NameNode，一遍故障 DataNode 在恢复后删除上面的不完整数据块。从管线中删除故障 DataNode 并把余下的数据块写入余下正常的 DataNode。NameNode 发现复本两不足时，会在另一个节点创建一个新的复本；


## HDFS的优缺点
HDFS优点：

- 数据冗余，硬件容错
- 处理流式的数据访问（一次写入，多次读取的操作）
- 适合存储大文件
- 可构建在廉价的机器上

缺点：

- 不适合低延迟的数据访问
- 不适合小文件的存储
- 不支持多用户写入及任意修改文件





